from __future__ import annotations

import os
import tempfile
from pathlib import Path

import pandas as pd
import streamlit as st
from dotenv import load_dotenv

from agent_enhanced import (
    build_advanced_agent,
    extract_sql_from_response,
    generate_analysis_summary,
    get_table_info_with_samples,
    render_schema_context,
    suggest_visualizations,
    validate_sql,
)
from duckdb_manager import DuckDBManager, create_in_memory_db

load_dotenv()

APP_TITLE = "AIæ•°æ®åˆ†æåŠ©æ‰‹ (Agno + DeepSeek + DuckDB)"
APP_DESCRIPTION = "ä¸Šä¼ CSV/Excelæ–‡ä»¶å¹¶ä½¿ç”¨è‡ªç„¶è¯­è¨€æé—®ã€‚é€šè¿‡AIç”ŸæˆSQLå®ç°å³æ—¶æ•°æ®åˆ†æã€‚"


def init_session_state() -> None:
    if "db_manager" not in st.session_state:
        st.session_state.db_manager = create_in_memory_db()
    
    if "uploaded_files" not in st.session_state:
        st.session_state.uploaded_files = {}
    
    if "analysis_history" not in st.session_state:
        st.session_state.analysis_history = []
    
    if "current_query" not in st.session_state:
        st.session_state.current_query = ""
    
    if "show_advanced" not in st.session_state:
        st.session_state.show_advanced = False


def reset_session() -> None:
    if "db_manager" in st.session_state:
        st.session_state.db_manager.close()
    
    st.session_state.clear()
    init_session_state()
    st.rerun()


def render_sidebar() -> None:
    with st.sidebar:
        st.title("âš™ï¸ è®¾ç½®")
        
        api_key = st.text_input(
            "DeepSeek APIå¯†é’¥",
            value=os.getenv("DEEPSEEK_API_KEY", ""),
            type="password",
            help="ä» https://platform.deepseek.com/ è·å–æ‚¨çš„APIå¯†é’¥"
        )
        
        st.session_state.api_key = api_key
        
        st.divider()
        
        st.subheader("ğŸ“Š æŸ¥è¯¢è®¾ç½®")
        row_limit = st.number_input(
            "é»˜è®¤è¡Œæ•°é™åˆ¶",
            min_value=10,
            max_value=10000,
            value=200,
            step=10,
            help="æŸ¥è¯¢è¿”å›çš„æœ€å¤§è¡Œæ•°"
        )
        st.session_state.row_limit = row_limit
        
        enable_explanations = st.checkbox(
            "æ˜¾ç¤ºSQLè§£é‡Š",
            value=False,
            help="åŒ…å«ç”ŸæˆSQLçš„è§£é‡Šè¯´æ˜"
        )
        st.session_state.enable_explanations = enable_explanations
        
        st.divider()
        
        st.subheader("ğŸ“ å·²åŠ è½½è¡¨")
        
        if st.session_state.db_manager:
            tables = st.session_state.db_manager.get_all_table_info()
            if tables:
                for table in tables:
                    with st.expander(f"ğŸ“Š {table.name}"):
                        st.write(f"**è¡Œæ•°:** {table.row_count:,}")
                        st.write(f"**å¤§å°:** {table.size_mb:.2f} MB")
                        
                        col1, col2 = st.columns(2)
                        with col1:
                            if st.button(f"é¢„è§ˆ", key=f"preview_{table.name}"):
                                st.session_state[f"preview_{table.name}"] = True
                        
                        with col2:
                            if st.button(f"ç»Ÿè®¡", key=f"stats_{table.name}"):
                                st.session_state[f"stats_{table.name}"] = True
                        
                        if st.session_state.get(f"preview_{table.name}", False):
                            sample = st.session_state.db_manager.get_table_sample(table.name, limit=5)
                            if sample is not None:
                                st.dataframe(sample, use_container_width=True)
                        
                        if st.session_state.get(f"stats_{table.name}", False):
                            stats = st.session_state.db_manager.get_table_statistics(table.name)
                            if stats:
                                st.json(stats, expanded=False)
            else:
                st.info("å°šæœªåŠ è½½ä»»ä½•è¡¨ã€‚è¯·åœ¨ä¸Šæ–¹ä¸Šä¼ æ–‡ä»¶ã€‚")
        
        st.divider()
        
        col1, col2 = st.columns(2)
        with col1:
            if st.button("ğŸ”„ é‡ç½®å·¥ä½œåŒº", use_container_width=True):
                reset_session()
        
        with col2:
            if st.button("ğŸ’¾ å¯¼å‡ºä¼šè¯", use_container_width=True):
                st.session_state.show_export = True
        
        st.divider()
        st.caption("ä½¿ç”¨ Agnoã€DeepSeek & DuckDB æ„å»º")


def render_file_upload() -> None:
    st.header("ğŸ“¤ ä¸Šä¼ æ•°æ®æ–‡ä»¶")
    
    col1, col2, col3 = st.columns(3)
    
    with col1:
        file_types = st.multiselect(
            "æ–‡ä»¶æ ¼å¼",
            options=["CSV", "Excel", "Parquet", "JSON"],
            default=["CSV", "Excel"],
            help="é€‰æ‹©æ”¯æŒçš„æ–‡ä»¶æ ¼å¼"
        )
    
    with col2:
        delimiter = st.selectbox(
            "CSVåˆ†éš”ç¬¦",
            options=[",", ";", "\t", "|"],
            index=0,
            help="CSVæ–‡ä»¶çš„åˆ—åˆ†éš”ç¬¦"
        )
    
    with col3:
        sheet_option = st.selectbox(
            "Excelå·¥ä½œè¡¨",
            options=["ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨", "æ‰€æœ‰å·¥ä½œè¡¨", "æŒ‡å®šåç§°"],
            index=0,
            help="Excelå·¥ä½œè¡¨åŠ è½½é€‰é¡¹"
        )
    
    uploaded_files = st.file_uploader(
        "é€‰æ‹©æ–‡ä»¶",
        type=get_file_extensions(file_types),
        accept_multiple_files=True,
        label_visibility="collapsed"
    )
    
    if uploaded_files:
        progress_bar = st.progress(0)
        
        for i, uploaded_file in enumerate(uploaded_files):
            file_key = f"{uploaded_file.name}_{uploaded_file.size}"
            
            if file_key in st.session_state.uploaded_files:
                st.info(f"æ–‡ä»¶ '{uploaded_file.name}' å·²åŠ è½½")
                continue
            
            with tempfile.NamedTemporaryFile(delete=False, suffix=Path(uploaded_file.name).suffix) as tmp_file:
                tmp_file.write(uploaded_file.getvalue())
                tmp_path = Path(tmp_file.name)
            
            try:
                file_suffix = Path(uploaded_file.name).suffix.lower()
                
                if file_suffix == ".csv":
                    table_name = st.session_state.db_manager.load_csv(
                        tmp_path, delimiter=delimiter
                    )
                elif file_suffix in [".xlsx", ".xls"]:
                    if sheet_option == "ç¬¬ä¸€ä¸ªå·¥ä½œè¡¨":
                        table_name = st.session_state.db_manager.load_excel(tmp_path, sheet_name=0)
                    elif sheet_option == "æ‰€æœ‰å·¥ä½œè¡¨":
                        try:
                            xls = pd.ExcelFile(tmp_path)
                            sheet_names = xls.sheet_names
                            tables_loaded = []
                            for sheet in sheet_names:
                                try:
                                    table_name = st.session_state.db_manager.load_excel(
                                        tmp_path, 
                                        sheet_name=sheet,
                                        table_name=f"{Path(uploaded_file.name).stem}_{sheet}"
                                    )
                                    tables_loaded.append(table_name)
                                except Exception as sheet_error:
                                    st.warning(f"å·¥ä½œè¡¨ '{sheet}' åŠ è½½å¤±è´¥: {str(sheet_error)}")
                            
                            if tables_loaded:
                                table_name = tables_loaded[0]
                                st.success(f"âœ… å·²åŠ è½½ {len(tables_loaded)} ä¸ªå·¥ä½œè¡¨: {', '.join(tables_loaded)}")
                            else:
                                raise ValueError("æ‰€æœ‰å·¥ä½œè¡¨åŠ è½½éƒ½å¤±è´¥äº†")
                        except Exception as e:
                            raise ValueError(f"åŠ è½½æ‰€æœ‰å·¥ä½œè¡¨å¤±è´¥: {str(e)}")
                    else:
                        sheet_name_input = st.text_input("è¯·è¾“å…¥å·¥ä½œè¡¨åç§°", key=f"sheet_name_{uploaded_file.name}")
                        if sheet_name_input:
                            table_name = st.session_state.db_manager.load_excel(tmp_path, sheet_name=sheet_name_input)
                        else:
                            raise ValueError("è¯·æŒ‡å®šå·¥ä½œè¡¨åç§°")
                elif file_suffix == ".parquet":
                    table_name = st.session_state.db_manager.load_parquet(tmp_path)
                elif file_suffix == ".json":
                    table_name = st.session_state.db_manager.load_json(tmp_path)
                else:
                    st.error(f"ä¸æ”¯æŒçš„æ–‡ä»¶æ ¼å¼: {file_suffix}")
                    continue
                
                st.session_state.uploaded_files[file_key] = {
                    "name": uploaded_file.name,
                    "table": table_name,
                    "size": uploaded_file.size
                }
                
                st.success(f"âœ… å·²åŠ è½½ '{uploaded_file.name}' ä¸ºè¡¨ `{table_name}`")
                
                table_info = st.session_state.db_manager.get_table_info(table_name)
                if table_info:
                    with st.expander(f"ğŸ“‹ Schema: {table_name}", expanded=False):
                        st.write(f"**åˆ—æ•°:** {len(table_info.columns)}")
                        for col_name, col_type in table_info.columns[:10]:
                            st.code(f"{col_name}: {col_type}")
                        if len(table_info.columns) > 10:
                            st.caption(f"... è¿˜æœ‰ {len(table_info.columns) - 10} åˆ—")
                
            except Exception as e:
                st.error(f"åŠ è½½æ–‡ä»¶ '{uploaded_file.name}' å¤±è´¥: {str(e)}")
                with st.expander("ğŸ› ï¸ è¯¦ç»†é”™è¯¯ä¿¡æ¯"):
                    st.text(str(e))
            finally:
                try:
                    if tmp_path.exists():
                        tmp_path.unlink(missing_ok=True)
                except Exception:
                    pass
            
            progress_bar.progress((i + 1) / len(uploaded_files))
        
        if uploaded_files:
            progress_bar.empty()


def get_file_extensions(file_types: list[str]) -> list[str]:
    extensions = []
    if "CSV" in file_types:
        extensions.extend([".csv", ".tsv"])
    if "Excel" in file_types:
        extensions.extend([".xlsx", ".xls"])
    if "Parquet" in file_types:
        extensions.extend([".parquet"])
    if "JSON" in file_types:
        extensions.extend([".json"])
    return extensions


def render_query_interface() -> None:
    st.header("ğŸ” å…³äºä½ çš„æ•°æ®æé—®")
    
    if not st.session_state.db_manager.get_table_names():
        st.info("ğŸ“ è¯·å…ˆä¸Šä¼ æ•°æ®æ–‡ä»¶ä»¥å¼€å§‹åˆ†æ")
        return
    
    col1, col2 = st.columns([3, 1])
    
    with col1:
        question = st.text_area(
            "ä½¿ç”¨è‡ªç„¶è¯­è¨€æé—®",
            placeholder="ä¾‹å¦‚ï¼š'æ˜¾ç¤ºå‰10åæ€»è´­ä¹°é¢æœ€é«˜çš„å®¢æˆ·' æˆ– 'æ¯æœˆçš„å¹³å‡é”€å”®é¢æ˜¯å¤šå°‘ï¼Ÿ'",
            height=100,
            key="question_input"
        )
    
    with col2:
        st.write("###")
        if st.button("ğŸš€ åˆ†æ", type="primary", use_container_width=True):
            st.session_state.current_query = question
        
        if st.button("ğŸ’¡ ç¤ºä¾‹é—®é¢˜", use_container_width=True):
            st.session_state.show_examples = True
    
    if st.session_state.get("show_examples", False):
        with st.expander("ğŸ“ ç¤ºä¾‹é—®é¢˜", expanded=True):
            examples = [
                "é”€å”®é¢æ’åå‰5çš„äº§å“æ˜¯ä»€ä¹ˆï¼Ÿ",
                "æ˜¾ç¤ºæœˆæ”¶å…¥è¶‹åŠ¿",
                "æŒ‰åœ°åŒºæ¯”è¾ƒé”€å”®é¢",
                "å¹³å‡å®¢æˆ·å¹´é¾„æ˜¯å¤šå°‘ï¼Ÿ",
                "åœ¨æ•°æ®ä¸­æŸ¥æ‰¾é‡å¤è®°å½•",
                "è®¡ç®—å¹´å¢é•¿ç‡",
                "æ˜¾ç¤ºè®¢å•å€¼çš„åˆ†å¸ƒæƒ…å†µ",
                "ä¸€å‘¨ä¸­å“ªå¤©çš„é”€å”®é¢æœ€é«˜ï¼Ÿ",
                "æŸ¥æ‰¾å˜é‡ä¹‹é—´çš„ç›¸å…³æ€§",
                "åŸºäºå†å²æ•°æ®é¢„æµ‹ä¸‹æœˆé”€å”®é¢"
            ]
            
            for example in examples:
                if st.button(example, use_container_width=True, key=f"example_{example}"):
                    st.session_state.current_query = example
                    st.rerun()
    
    if st.session_state.current_query and st.session_state.api_key:
        process_query(st.session_state.current_query)


def process_query(question: str) -> None:
    with st.spinner("ğŸ¤– ç”ŸæˆSQLæŸ¥è¯¢..."):
        tables = get_table_info_with_samples(st.session_state.db_manager.connection)
        schema_context = render_schema_context(tables, include_samples=True)
        
        agent = build_advanced_agent(
            api_key=st.session_state.api_key,
            schema_context=schema_context,
            enable_explanations=st.session_state.enable_explanations
        )
        
        response = agent.run(question)
        sql = extract_sql_from_response(response, st.session_state.enable_explanations)
    
    if not sql:
        st.error("AIä»£ç†æœªç”Ÿæˆæœ‰æ•ˆçš„SQLã€‚è¯·å°è¯•é‡æ–°è¡¨è¿°æ‚¨çš„é—®é¢˜ã€‚")
        return
    
    st.subheader("ğŸ“„ ç”Ÿæˆçš„SQL")
    st.code(sql, language="sql")
    
    with st.spinner("ğŸ” éªŒè¯å¹¶æ‰§è¡ŒæŸ¥è¯¢..."):
        is_valid, validation_msg = validate_sql(sql, st.session_state.db_manager.connection)
        
        if not is_valid:
            st.error(f"SQLéªŒè¯å¤±è´¥: {validation_msg}")
            return
        
        st.success(f"âœ… SQLéªŒè¯é€šè¿‡: {validation_msg}")
        
        if "limit" not in sql.lower():
            sql = f"{sql.rstrip(';')} LIMIT {st.session_state.row_limit}"
        
        result = st.session_state.db_manager.execute_query(sql)
    
    if result.success:
        display_query_results(result, question, sql)
    else:
        st.error(f"æŸ¥è¯¢æ‰§è¡Œå¤±è´¥: {result.error}")
        
        with st.expander("ğŸ› ï¸ è°ƒè¯•ä¿¡æ¯"):
            st.write("**Schemaä¸Šä¸‹æ–‡:**")
            st.text(schema_context[:500] + "..." if len(schema_context) > 500 else schema_context)
            
            st.write("**Agentå“åº”:**")
            st.text(str(response)[:500] + "..." if len(str(response)) > 500 else str(response))


def display_query_results(result, question: str, sql: str) -> None:
    df = result.data
    
    st.subheader("ğŸ“Š ç»“æœ")
    
    tabs = st.tabs(["ğŸ“‹ æ•°æ®", "ğŸ“ˆ æ‘˜è¦", "ğŸ“Š å¯è§†åŒ–", "ğŸ’¾ å¯¼å‡º"])
    
    with tabs[0]:
        st.dataframe(df, use_container_width=True)
        
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è¡Œæ•°", f"{len(df):,}")
        with col2:
            st.metric("åˆ—æ•°", len(df.columns))
        with col3:
            st.metric("æ‰§è¡Œæ—¶é—´", f"{result.execution_time_ms:.1f} æ¯«ç§’")
    
    with tabs[1]:
        summary = generate_analysis_summary(df)
        
        st.subheader("ç»Ÿè®¡æ‘˜è¦")
        
        if "numeric_columns" in summary:
            st.write("**æ•°å€¼åˆ—:**")
            for col in summary["numeric_columns"][:5]:
                if f"{col}_stats" in summary:
                    stats = summary[f"{col}_stats"]
                    col1, col2, col3, col4 = st.columns(4)
                    with col1:
                        st.metric("æœ€å°å€¼", f"{stats.get('min', 0):.2f}")
                    with col2:
                        st.metric("æœ€å¤§å€¼", f"{stats.get('max', 0):.2f}")
                    with col3:
                        st.metric("å¹³å‡å€¼", f"{stats.get('mean', 0):.2f}")
                    with col4:
                        st.metric("æ ‡å‡†å·®", f"{stats.get('std', 0):.2f}")
        
        if "string_columns" in summary:
            st.write("**å­—ç¬¦ä¸²åˆ—:**")
            for col in summary["string_columns"][:3]:
                if f"{col}_info" in summary:
                    info = summary[f"{col}_info"]
                    st.write(f"**{col}:** {info.get('unique_count', 0)} ä¸ªå”¯ä¸€å€¼")
                    if info.get("sample_values"):
                        st.write(f"ç¤ºä¾‹: {', '.join(map(str, info['sample_values'][:3]))}")
        
        st.divider()
        st.write("**æ•°æ®ç±»å‹:**")
        for col, dtype in summary.get("data_types", {}).items():
            st.code(f"{col}: {dtype}")
    
    with tabs[2]:
        if not df.empty:
            suggestions = suggest_visualizations(df)
            
            st.write("**å»ºè®®çš„å¯è§†åŒ–:**")
            for suggestion in suggestions:
                st.write(f"â€¢ {suggestion}")
            
            st.divider()
            
            numeric_cols = df.select_dtypes(include="number").columns.tolist()
            categorical_cols = df.select_dtypes(include="object").columns.tolist()
            date_cols = [col for col in df.columns if "date" in col.lower() or "time" in col.lower()]
            
            if numeric_cols and (len(categorical_cols) >= 1 or len(date_cols) >= 1):
                st.subheader("åˆ›å»ºå¯è§†åŒ–")
                
                viz_type = st.selectbox(
                    "å›¾è¡¨ç±»å‹",
                    options=["æŠ˜çº¿å›¾", "æŸ±çŠ¶å›¾", "æ•£ç‚¹å›¾", "é¢ç§¯å›¾", "ç›´æ–¹å›¾", "ç®±çº¿å›¾"],
                    index=0
                )
                
                col1, col2 = st.columns(2)
                with col1:
                    x_col = st.selectbox(
                        "Xè½´",
                        options=df.columns.tolist(),
                        index=0
                    )
                
                with col2:
                    if viz_type in ["ç›´æ–¹å›¾", "ç®±çº¿å›¾"]:
                        y_col = st.selectbox(
                            "æ•°å€¼åˆ—",
                            options=numeric_cols,
                            index=0 if numeric_cols else None
                        )
                    else:
                        y_col = st.selectbox(
                            "Yè½´",
                            options=numeric_cols,
                            index=0 if numeric_cols else None
                        )
                
                if viz_type == "æŠ˜çº¿å›¾" and x_col and y_col:
                    chart_data = df[[x_col, y_col]].set_index(x_col)
                    st.line_chart(chart_data)
                elif viz_type == "æŸ±çŠ¶å›¾" and x_col and y_col:
                    chart_data = df[[x_col, y_col]].set_index(x_col)
                    st.bar_chart(chart_data)
                elif viz_type == "æ•£ç‚¹å›¾" and x_col and y_col:
                    st.scatter_chart(df, x=x_col, y=y_col)
                elif viz_type == "é¢ç§¯å›¾" and x_col and y_col:
                    chart_data = df[[x_col, y_col]].set_index(x_col)
                    st.area_chart(chart_data)
                elif viz_type == "ç›´æ–¹å›¾" and y_col:
                    st.bar_chart(df[y_col].value_counts().sort_index())
                elif viz_type == "ç®±çº¿å›¾" and y_col:
                    if categorical_cols:
                        group_col = st.selectbox("åˆ†ç»„ä¾æ®", categorical_cols)
                        groups = df[group_col].unique()
                        for group in groups[:5]:
                            group_data = df[df[group_col] == group][y_col]
                            st.write(f"**{group}:** æœ€å°å€¼={group_data.min():.2f}, æœ€å¤§å€¼={group_data.max():.2f}, å¹³å‡å€¼={group_data.mean():.2f}")
                    else:
                        st.write(f"**{y_col}çš„ç»Ÿè®¡ä¿¡æ¯:**")
                        st.write(f"æœ€å°å€¼={df[y_col].min():.2f}, æœ€å¤§å€¼={df[y_col].max():.2f}, å¹³å‡å€¼={df[y_col].mean():.2f}")
            
            elif numeric_cols and len(numeric_cols) >= 2:
                st.subheader("ç›¸å…³çŸ©é˜µ")
                corr_matrix = df[numeric_cols].corr()
                st.dataframe(corr_matrix.round(3))
    
    with tabs[3]:
        st.subheader("å¯¼å‡ºé€‰é¡¹")
        
        export_format = st.selectbox(
            "å¯¼å‡ºæ ¼å¼",
            options=["CSV", "Excel", "JSON", "Parquet"],
            index=0
        )
        
        export_filename = st.text_input(
            "æ–‡ä»¶å",
            value=f"analysis_export_{pd.Timestamp.now().strftime('%Y%m%d_%H%M%S')}",
            help="å¯¼å‡ºæ–‡ä»¶çš„åç§°ï¼ˆä¸å«æ‰©å±•åï¼‰"
        )
        
        if st.button("ğŸ“¥ å¯¼å‡ºæ•°æ®", type="primary"):
            with tempfile.TemporaryDirectory() as tmpdir:
                tmp_path = Path(tmpdir) / f"{export_filename}.{export_format.lower()}"
                
                try:
                    if export_format == "CSV":
                        df.to_csv(tmp_path, index=False)
                    elif export_format == "Excel":
                        df.to_excel(tmp_path, index=False)
                    elif export_format == "JSON":
                        df.to_json(tmp_path, orient="records", indent=2)
                    elif export_format == "Parquet":
                        df.to_parquet(tmp_path, index=False)
                    
                    with open(tmp_path, "rb") as f:
                        st.download_button(
                            label=f"ä¸‹è½½ {export_format} æ–‡ä»¶",
                            data=f,
                            file_name=f"{export_filename}.{export_format.lower()}",
                            mime={
                                "CSV": "text/csv",
                                "Excel": "application/vnd.openxmlformats-officedocument.spreadsheetml.sheet",
                                "JSON": "application/json",
                                "Parquet": "application/octet-stream"
                            }[export_format]
                        )
                    
                    st.success(f"æ•°æ®å·²æˆåŠŸå¯¼å‡ºä¸º {export_format} æ ¼å¼")
                except Exception as e:
                    st.error(f"å¯¼å‡ºå¤±è´¥: {str(e)}")
        
        st.divider()
        
        st.subheader("ä¿å­˜åˆ†æåˆ°å†å²è®°å½•")
        if st.button("ğŸ’¾ ä¿å­˜åˆ°å†å²è®°å½•"):
            analysis_entry = {
                "timestamp": pd.Timestamp.now().isoformat(),
                "question": question,
                "sql": sql,
                "row_count": len(df),
                "execution_time": result.execution_time_ms,
                "columns": list(df.columns)
            }
            
            st.session_state.analysis_history.append(analysis_entry)
            st.success("åˆ†æå·²ä¿å­˜åˆ°å†å²è®°å½•ï¼")
    
    st.session_state.analysis_history.append({
        "timestamp": pd.Timestamp.now().isoformat(),
        "question": question,
        "sql": sql,
        "row_count": len(df),
        "execution_time": result.execution_time_ms
    })


def render_history() -> None:
    if not st.session_state.analysis_history:
        return
    
    st.header("ğŸ“œ åˆ†æå†å²")
    
    for i, entry in enumerate(reversed(st.session_state.analysis_history[-10:])):
        with st.expander(f"æŸ¥è¯¢ {len(st.session_state.analysis_history) - i}: {entry['question'][:50]}..."):
            st.write(f"**æ—¶é—´:** {entry['timestamp']}")
            st.write(f"**é—®é¢˜:** {entry['question']}")
            st.code(entry['sql'], language="sql")
            st.write(f"**ç»“æœ:** {entry.get('row_count', 0)} è¡Œ, {entry.get('execution_time', 0):.1f} æ¯«ç§’")
            
            if st.button(f"é‡æ–°è¿è¡ŒæŸ¥è¯¢", key=f"rerun_{i}"):
                st.session_state.current_query = entry['question']
                st.rerun()


def main() -> None:
    st.set_page_config(
        page_title=APP_TITLE,
        page_icon="ğŸ“Š",
        layout="wide",
        initial_sidebar_state="expanded"
    )
    
    st.title(APP_TITLE)
    st.markdown(APP_DESCRIPTION)
    
    init_session_state()
    render_sidebar()
    
    render_file_upload()
    render_query_interface()
    render_history()
    
    st.divider()
    st.caption("âœ¨ ç”± [Agno](https://github.com/agno-agi/agno)ã€[DeepSeek](https://platform.deepseek.com/)ã€[DuckDB](https://duckdb.org/) å’Œ [Streamlit](https://streamlit.io/) æä¾›æ”¯æŒ")


if __name__ == "__main__":
    main()